{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc29434-f79f-4f94-8b40-8c0ee9c1af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import environments.mountain_car as mc\n",
    "from useful import trees\n",
    "from agents import dqn_agent\n",
    "from agents import ddqn_agent\n",
    "from agents import pddqn_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431366b6-a192-4140-899f-d50660189c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef11db-5d2b-44f0-9ae9-82c771093fa4",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1957ced-1b72-4973-9ce9-861a61219fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mountain_car_model_1(nn.Module): \n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(mountain_car_model_1, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_observations, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b848b60-d190-4b47-826c-aab817396f53",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027605c-6a06-462e-8e21-f60f7e3b1298",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def testing(env, agent, n_episodes, file_name, options = None):\n",
    "    \"\"\"\n",
    "    Training agents for the mountain car environment. Provides the mean positions as a graph with the mean rewards. \n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    env: gym environment\n",
    "    agent: training agent\n",
    "    n_episodes: an integer for the number of episodes to run\n",
    "    file_name: a string name of the model to import\n",
    "    options: a dict that changes the environment\n",
    "    ------\n",
    "    output\n",
    "    ------\n",
    "    reward_list: a list of the total reward per episode\n",
    "    state_list: a list of states per episode\n",
    "    starting_positions: a list of starting positions\n",
    "    \"\"\"\n",
    "    agent.main_model.load_state_dict(torch.load(f\"model_weights/mountain_car/{file_name}.pth\"))\n",
    "    agent.main_model.eval()\n",
    "    reward_list, state_list, starting_positions, global_steps, success = [], [], [], 0, 0\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        total_reward, position_list = 0, []\n",
    "        state, _ = env.reset(options = options)\n",
    "        starting_positions.append(state[0])\n",
    "\n",
    "        for step in range(env.max_steps):\n",
    "            global_steps += 1\n",
    "            position_list.append(state)\n",
    "\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, termination, truncation, _ = env.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if termination:\n",
    "                success += 1\n",
    "                break\n",
    "            if truncation:\n",
    "                break\n",
    "\n",
    "        position_list.append(state)\n",
    "        reward_list.append(total_reward)\n",
    "        state_list.append(position_list)\n",
    "    \n",
    "    print(f\"Success Rate: {100 * success/n_episodes:.2f}% | Mean Reward: {np.mean(reward_list):.2f}\")\n",
    "\n",
    "    return reward_list, state_list, starting_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c1e97-b691-4938-8971-503c01e663f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def positions_to_rewards(reward_list, starting_positions, move):\n",
    "    \"\"\"\n",
    "    Takes starting positions and converts them to the reward for the episode\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    reward_list: a list of rewards \n",
    "    starting_positions: a list of starting_positions\n",
    "    move: a list for how to move each line \n",
    "    ------\n",
    "    Output\n",
    "    ------\n",
    "    position_bounds: a dict with the bounds and the corresponding rewards\n",
    "    \"\"\"\n",
    "    position_bounds = {\"bound_1\": [], \"bound_2\": [], \"bound_3\": [], \"bound_4\": []}\n",
    "    \n",
    "    for i, j in zip(reward_list, starting_positions):\n",
    "        if -0.6 + move <= j < -0.55 + move:\n",
    "            position_bounds[\"bound_1\"].append(i)\n",
    "        elif -0.55 + move <= j < -0.5 + move:\n",
    "            position_bounds[\"bound_2\"].append(i)\n",
    "        elif -0.5 + move <= j < -0.45 + move:\n",
    "            position_bounds[\"bound_3\"].append(i)\n",
    "        else:\n",
    "            position_bounds[\"bound_4\"].append(i)\n",
    "\n",
    "    return position_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80f4ee-2a94-4a4a-befe-75016e30d9a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_bars(reward_list, starting_positions, legends, title, moved = [], move = 0):\n",
    "    \"\"\"\n",
    "    A function that plot a grouped bar plot\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    reward_list: a list of rewards \n",
    "    starting_positions: a list of starting_positions\n",
    "    legends: a list of annotations\n",
    "    title: a string for the title\n",
    "    moved: a list for changing the x labels \n",
    "    move: adjust to seperate the startin positions\n",
    "    \"\"\"\n",
    "    if moved: \n",
    "        bounds = moved\n",
    "    else:\n",
    "        bounds = [\"[-0.6, -0.55)\", \"[-0.55, -0.5)\", \"[-0.5, -0.45)\", \"[-0.45, -0.4)\"]\n",
    "    x = np.arange(len(bounds))\n",
    "    width = 0.2\n",
    "\n",
    "    plt.figure(figsize = (4.5, 3))\n",
    "    \n",
    "    for i in range(len(legends)):\n",
    "        position_bounds = positions_to_rewards(reward_list = reward_list[i], starting_positions = starting_positions[i], move = move)\n",
    "        means = [np.mean(i) for i in position_bounds.values()]\n",
    "        stds = [np.std(i) for i in position_bounds.values()]\n",
    "\n",
    "        plt.bar(x + (i - (len(legends) - 1)/2) * width, means, width = width, yerr = stds, label = legends[i])\n",
    "\n",
    "    plt.xticks(x, bounds)\n",
    "    plt.title(f\"{title}\")\n",
    "    plt.xlabel(\"Starting Position Bounds\")\n",
    "    plt.ylabel(\"Average Reward\")\n",
    "    #plt.xticks(rotation = 10) \n",
    "    plt.grid(alpha = 0.25)\n",
    "\n",
    "    plt.legend(fontsize = 8, loc = \"upper center\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"_comparison.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648b45f-860b-44b7-b9b2-624211e7f38f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_episode(state_list):\n",
    "    \"\"\"\n",
    "    A function that plots random episodes\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    state_list: a list of states\n",
    "    \"\"\"\n",
    "    figs, axes = plt.subplots(1, 6, figsize = (18, 1.5))\n",
    "\n",
    "    for j in range(6):\n",
    "        random = np.random.randint(0, len(state_list))\n",
    "        position_1 = [state[0] for state in state_list[random]]\n",
    "        min_y, max_y = min(position_1), max(position_1)\n",
    "        axes[j].plot(position_1, label = f\"{position_1[0]:.2f}\")\n",
    "        axes[j].grid(alpha = 0.25)\n",
    "        axes[j].set_ylim(min_y, max_y)\n",
    "        axes[j].set_yticks([min_y, max_y])\n",
    "        #axes[j].set_yticks(np.linspace(min_y, max_y, 4))\n",
    "        axes[j].legend(loc = \"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"_runs.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7ca81-9355-406b-bf0f-9dfd62eee18f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_terrain(move, x, y, title):\n",
    "    \"\"\"\n",
    "    Plots the terrain for the episode\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    move: a list for how to move each line\n",
    "    x: an array of x values\n",
    "    y: an array of y values\n",
    "    title: a string for the title\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (3, 2))\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{title}\")\n",
    "    plt.xlabel(\"Position\")\n",
    "    plt.ylabel(\"Height\")\n",
    "    plt.axvline(-1.2 + move[0], color = \"black\", label = \"Wall\")\n",
    "    plt.axvline(0.5 + move[1], color = \"r\", linestyle = \"--\", label = \"Flag\")\n",
    "    plt.axvline(-0.6 + move[2], color = \"g\", linestyle = \"--\", label = \"Start\")\n",
    "    plt.axvline(-0.4 + move[3], color = \"g\", linestyle = \"--\")\n",
    "\n",
    "    #plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739833bf-dbe5-42de-b69b-065cefae6472",
   "metadata": {},
   "source": [
    "# Standard Mountain Car Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b98116-cab9-47d6-82cc-15d070c8316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "move = [0, 0, 0, 0]\n",
    "x = np.linspace(-1.2, 0.6, 500) \n",
    "y = np.sin(3 * x)      \n",
    "\n",
    "plot_terrain(move = move, x = x, y = y, title = \"Standard Terrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16581a8f-94a1-4fed-985e-f07f92e485c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.mountain_car_discrete_v1()\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv1_rewards, mcv1_states, mcv1_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv1/mcv1_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4e3c5-abae-4819-b49d-3952e4591360",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv1_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972e0ad-8baf-4819-ad6e-2b2068ea3173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.mountain_car_discrete_v1()\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv2_rewards, mcv2_states, mcv2_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv2/mcv2_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297062b-8e08-470a-8ae5-434efe967852",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv2_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6c412-3996-4577-a0c9-33b281b99169",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list = [mcv1_rewards, mcv2_rewards]\n",
    "starting_positions = [mcv1_sp, mcv2_sp]\n",
    "legends = [\"MCV1\", \"MCV2\"]\n",
    "\n",
    "plot_bars(reward_list = reward_list, starting_positions = starting_positions, legends = legends, title = \"Standard Environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd1d84-1391-4f68-a700-e73befdc35b1",
   "metadata": {},
   "source": [
    "# Changing Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e3f92-d5a2-4e04-a0c0-ed4622f3585f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.mountain_car_discrete_v1()\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv1_f_rewards, mcv1_f_states, mcv1_f_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv1/mcv1_5\", options = {\"force\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d11e9a-a21d-407e-921c-3eaa10c51f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv1_f_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f81f2-4a72-4e07-992c-9ca13a113729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.mountain_car_discrete_v1()\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv2_f_rewards, mcv2_f_states, mcv2_f_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv2/mcv2_8\", options = {\"force\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3d7e6-0f34-4331-9b38-bea0b847d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv2_f_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499480cd-a422-407f-8ed1-14afd09ddf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list = [mcv1_f_rewards, mcv2_f_rewards]\n",
    "starting_positions = [mcv1_f_sp, mcv2_f_sp]\n",
    "legends = [\"MCV1\", \"MCV2\"]\n",
    "\n",
    "plot_bars(reward_list = reward_list, starting_positions = starting_positions, legends = legends, title = \"Force: 0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382eadd-40fb-45db-80fe-09e6274aa947",
   "metadata": {},
   "source": [
    "# Testing a Steeper Hill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ee116-93d7-417c-8479-aac39c8ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "move = [0, 0, 0, 0]\n",
    "x = np.linspace(-1.2, 0.6, 500) \n",
    "y = 1.5 * np.sin(3 * x)        \n",
    "\n",
    "plot_terrain(move = move, x = x, y = y, title = \"Steeper Terrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa25d9-8d23-4861-8b39-6e57afe8547e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.steeper_hill() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv1_steeper_rewards, mcv1_steeper_states, mcv1_steeper_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv1/mcv1_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148b272-651b-4792-9ea9-90eb4161e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv1_steeper_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30597cd-6911-4106-83f3-85defa0ad451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.steeper_hill() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv2_steeper_rewards, mcv2_steeper_states, mcv2_steeper_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv2/mcv2_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a237028e-feab-4b75-99bb-81a2e75886e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv2_steeper_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1987751-0a10-462c-9398-f514e7938ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list = [mcv1_steeper_rewards, mcv2_steeper_rewards]\n",
    "starting_positions = [mcv1_steeper_sp, mcv2_steeper_sp]\n",
    "legends = [\"MCV1\", \"MCV2\"]\n",
    "\n",
    "plot_bars(reward_list = reward_list, starting_positions = starting_positions, legends = legends, title = \"Steeper Hill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc2f6cd-b0fe-4968-8b86-e08be54dd385",
   "metadata": {},
   "source": [
    "# Mirrored Terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3618e8-b512-4952-a6f2-44c7a90e0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "move = [3.4, 0, 2.0, 2.0]\n",
    "x = np.linspace(0.4, 2.2, 500) \n",
    "y = np.sin(3 * x)  \n",
    "\n",
    "plot_terrain(move = move, x = x, y = y, title = \"Mirrored Terrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a8fc0-601e-444b-ab7b-2efc3bc7dda9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.mirrored_terrain() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv1_mirrored_rewards, mcv1_mirrored_states, mcv1_mirrored_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv1/mcv1_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ffd62e-1566-42f9-979f-6800219f3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv1_mirrored_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731dfa9-61f4-49d6-b5e5-d95419b52065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.mirrored_terrain()\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv2_mirrored_rewards, mcv2_mirrored_states, mcv2_mirrored_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv2/mcv2_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983978c-b219-4c80-98ba-ef604333e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv2_mirrored_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b661c-7f4f-433a-9731-4b8816ca4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list = [mcv1_mirrored_rewards, mcv2_mirrored_rewards]\n",
    "starting_positions = [mcv1_mirrored_sp, mcv2_mirrored_sp]\n",
    "legends = [\"MCV1\", \"MCV2\"]\n",
    "moved = [\"[1.4, 1.45)\", \"[1.45, 1.5)\", \"[1.5, 1.55)\", \"[1.55, 1.6)\"]\n",
    "move = 2.0\n",
    "\n",
    "plot_bars(reward_list = reward_list, starting_positions = starting_positions, legends = legends, title = \"Mirrored Terrain\", moved = moved, move = move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8facd4f2-d577-497c-a2fc-7b565a18a2ba",
   "metadata": {},
   "source": [
    "# Extended Track Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a38e674-9726-4a3c-9fbc-0adc66a90d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 2 * np.pi/3\n",
    "move = [-value, 0, -value, -value]\n",
    "x = np.linspace(-1.2 - value, 0.6, 500) \n",
    "y = np.sin(3 * x)   \n",
    "\n",
    "plot_terrain(move = move, x = x, y = y, title = \"Exteneded Terrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232904c6-09d6-4947-865d-d7d1d51145ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.extended_track() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv1_extended_rewards, mcv1_extended_states, mcv1_extended_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv1/mcv1_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece99c5b-77cd-4a7e-9ade-fcdbc38785c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv1_extended_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea71c7-f9d2-4707-ac8a-8ca460aee587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = mc.extended_track()\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "mcv2_extended_rewards, mcv2_extended_states, mcv2_extended_sp = testing(env = env, agent = agent, n_episodes = 1000, file_name = \"mcv2/mcv2_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df44922-7b9e-4fd1-9443-d815fdd84dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode(state_list = mcv2_extended_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d53b702-eedc-47b1-9560-72012f6352b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list = [mcv1_extended_rewards, mcv2_extended_rewards]\n",
    "starting_positions = [mcv1_extended_sp, mcv2_extended_sp]\n",
    "legends = [\"MCV1\", \"MCV2\"]\n",
    "moved = [\"[-2.69, -2.64)\", \"[-2.64, -2.59)\", \"[-2.59, -2.54)\", \"[-2.54, -2.49)\"]\n",
    "move = -2 * np.pi/3\n",
    "\n",
    "plot_bars(reward_list = reward_list, starting_positions = starting_positions, legends = legends, title = \"Extended Track Length\", moved = moved, move = move)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
