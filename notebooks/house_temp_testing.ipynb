{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d5855-aa6b-4342-88c8-5f228b471f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import environments.house_temp as ht\n",
    "from useful import trees\n",
    "from agents import dqn_agent\n",
    "from agents import ddqn_agent\n",
    "from agents import pddqn_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37517923-f0ff-4ee4-84d1-39c569eee641",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9524232c-c76e-4b63-ac99-e91cdeb6d5c3",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77af1e0-604e-4300-b86a-fce68163a7a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class house_temp_model_1(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(house_temp_model_1, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_observations, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cebd7-fe7c-4f5a-893e-941a0e75d80f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class house_temp_model_2(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(house_temp_model_2, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_observations, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f145c7-a47d-43e7-95c5-5c796598311e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class house_temp_model_3(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(house_temp_model_3, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_observations, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d98e0-3039-4885-9769-6398e456df9e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class dueling_dqn_htm3(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(dueling_dqn_htm3, self).__init__()\n",
    "        self.n_observations = n_observations\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_observations, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.state_value = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.shape == torch.Size([self.n_observations]):\n",
    "            x = x.unsqueeze(0)\n",
    "        \n",
    "        x = self.model(x)\n",
    "        value = self.state_value(x)\n",
    "        advantage = self.advantage(x)\n",
    "        q_value = value + (advantage - torch.mean(advantage, dim = 1, keepdim = True))\n",
    "        \n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd814b-fe47-401d-941c-11f39cb3721b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58bf69-9c3b-45fa-ac48-86fa7111ddd1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def testing(env, agent, n_episodes, file_name, options = None):\n",
    "    \"\"\"\n",
    "    Testing agents for the house temperature environment \n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    env: gym environment\n",
    "    agent: training agent\n",
    "    n_episodes: number of episodes to run\n",
    "    file_name: file name for saving the model \n",
    "    options: dict to alter the environment\n",
    "    ------\n",
    "    Output\n",
    "    ------\n",
    "    reward_array: an array of the total reward per episode\n",
    "    action_dict: a dict of the total actions taken per action \n",
    "    ep_state_list: a list of states per episode\n",
    "    \"\"\"\n",
    "    agent.main_model.load_state_dict(torch.load(f\"model_weights/house_temp/{file_name}.pth\"))\n",
    "    agent.main_model.eval()\n",
    "    reward_array, action_dict, ep_state_list, reward_list = np.zeros((n_episodes, env.max_steps)), {}, [], []\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        state, _ = env.reset(options = options)\n",
    "        total_reward, reward, state_list, steps_loss = 0, 0, [], []\n",
    "        \n",
    "        for steps in range(env.max_steps):\n",
    "            state_list.append(state)\n",
    "            action = agent.act(state)\n",
    "            if action not in action_dict:\n",
    "                action_dict[action] = 1\n",
    "            else:\n",
    "                action_dict[action] += 1\n",
    "\n",
    "            next_state, reward, termination, truncation, _ = env.step(action)\n",
    "            reward_array[episode, steps] = reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            state = next_state\n",
    "            if termination or truncation:\n",
    "                break\n",
    "\n",
    "        reward_list.append(total_reward)\n",
    "        ep_state_list.append(state_list)\n",
    "\n",
    "    print(f\"Average Reward: {np.mean(reward_list):.2f}\")\n",
    "    \n",
    "    return reward_array, action_dict, ep_state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f5aec-db4e-4fd6-894e-b6649ef4bb85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def in_target_v2(state_list):\n",
    "    \"\"\"\n",
    "    Analyses the states into metrics for version 2\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    state_list: a list of states\n",
    "    \"\"\"\n",
    "    in_target_total, preheating_total = [], [] \n",
    "    for episode in state_list:\n",
    "        steps, in_target, preheating = 0, 0, 0\n",
    "        for state in episode:\n",
    "            inside, outside, target, next_target, time, heater, cooler = state\n",
    "\n",
    "            if target - 1.0 < inside < target + 1.0:\n",
    "                in_target += 1\n",
    "                \n",
    "            if time == 30 and steps > 0:\n",
    "                if target - 1.0 < inside < target + 1.0:\n",
    "                    preheating += 1\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "        in_target_total.append(in_target)\n",
    "        preheating_total.append(preheating)\n",
    "\n",
    "    print(f\"In target temperature range: {100 * np.mean(in_target_total)/288:.2f}%\")\n",
    "    print(f\"In preheating/cooling range: {100 * np.mean(preheating_total)/9:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a659bc-3d28-4025-ac7c-0dbf1efc4d19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def in_target_v3(state_list):\n",
    "    \"\"\"\n",
    "    Analyses the states into metrics for version 3\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    state_list: a list of states\n",
    "    \"\"\"\n",
    "    in_target_total, preheating_total, heater_total, cooler_total, window_total, ep_step = [], [], [], [], [], []\n",
    "    for episode in state_list:\n",
    "        steps, in_target, preheating, heater_v, cooler_v, window_v = 0, 0, 0, 0, 0, 0\n",
    "        for state in episode:\n",
    "            inside, outside, target, next_target, time, heater, cooler, window = state\n",
    "            heater_v += heater\n",
    "            cooler_v += cooler\n",
    "            window_v += window\n",
    "            energy = heater * 0.5 + cooler * 0.5\n",
    "            ep_step.append(energy)\n",
    "            \n",
    "            if target - 1.0 < inside < target + 1.0:\n",
    "                in_target += 1\n",
    "                \n",
    "            if time == 24 and steps > 0:\n",
    "                if target - 1.0 < inside < target + 1.0:\n",
    "                    preheating += 1\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "        in_target_total.append(in_target)\n",
    "        preheating_total.append(preheating)\n",
    "        heater_total.append(heater_v)\n",
    "        cooler_total.append(cooler_v)\n",
    "        window_total.append(window_v)\n",
    "\n",
    "    print(f\"In target temperature range: {100 * np.mean(in_target_total)/288:.2f}%\")\n",
    "    print(f\"In preheating/cooling range: {100 * np.mean(preheating_total)/9:.2f}%\")\n",
    "    print(f\"Heater Used: {100 * np.mean(heater_total)/288:.2f}% | Cooler Used: {100 * np.mean(cooler_total)/288:.2f}% | Window Used: {100 * np.mean(window_total)/288:.2f}%\")\n",
    "    print(f\"Average Energy Per Step: {np.mean(ep_step):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5320cf6d-43bc-4a35-bb3f-f4b360ba65c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def in_target_v4(state_list, switch_value = 24):\n",
    "    \"\"\"\n",
    "    Analyses the states into metrics for version 4\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    state_list: a list of states\n",
    "    swtich_value: how often the target temperature changes\n",
    "    \"\"\"\n",
    "    in_target_total, preheating_total, heater_total, cooler_total, window_total, ep_step = [], [], [], [], [], []\n",
    "    for episode in state_list:\n",
    "        steps, counter, in_target, preheating, heater_v, cooler_v, window_v = 0, 0, 0, 0, 0, 0, 0\n",
    "        for state in episode:\n",
    "            inside, outside, next_outside, target, next_target, time, heater, cooler, window = state\n",
    "            heater_v += heater\n",
    "            cooler_v += cooler\n",
    "            window_v += window\n",
    "            energy = heater * 0.5 + cooler * 0.5\n",
    "            ep_step.append(energy)\n",
    "\n",
    "            if target - 0.5 < inside < target + 0.5:\n",
    "                in_target += 1\n",
    "                \n",
    "            if time == switch_value and steps > 0:\n",
    "                counter += 1\n",
    "                if target - 0.5 < inside < target + 0.5:\n",
    "                    preheating += 1\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "        in_target_total.append(in_target)\n",
    "        preheating_total.append(preheating)\n",
    "        heater_total.append(heater_v)\n",
    "        cooler_total.append(cooler_v)\n",
    "        window_total.append(window_v)\n",
    "\n",
    "    print(f\"In target temperature range: {100 * np.mean(in_target_total)/288:.2f}%\")\n",
    "    print(f\"In preheating/cooling range: {100 * np.mean(preheating_total)/counter:.2f}%\")\n",
    "    print(f\"Heater Used: {100 * np.mean(heater_total)/288:.2f}% | Cooler Used: {100 * np.mean(cooler_total)/288:.2f}% | Window Used: {100 * np.mean(window_total)/288:.2f}%\")\n",
    "    print(f\"Average Energy Per Step: {np.mean(ep_step):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c89a3b5-af56-429b-b5f2-0ef38f75434a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_ra(max_steps, rewards, actions, action_space, version):\n",
    "    \"\"\"\n",
    "    Plots rewards per step and total actions\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    max_steps: an integer number of total steps\n",
    "    rewards: a list of rewards\n",
    "    actions: a dict of actions\n",
    "    action_space: a dict of action meaning\n",
    "    version: a string for the version\n",
    "    \"\"\"\n",
    "    x = [i for i in range(max_steps)] \n",
    "    mean, std = np.mean(rewards, axis = 0), np.std(rewards, axis = 0)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize = (20, 6.667))\n",
    "\n",
    "    axes[0].plot(x, mean)\n",
    "    axes[0].fill_between(x, mean - std, mean + std, alpha = 0.25)\n",
    "    axes[0].set_title(f\"Testing | DDQN | MSE | {version}\")\n",
    "    axes[0].set_ylabel(\"Mean Reward\")\n",
    "    axes[0].set_xlabel(\"Steps\")\n",
    "    axes[0].grid()\n",
    "    \n",
    "    for key, value in actions.items():\n",
    "        axes[1].bar(action_space[key], value)\n",
    "    axes[1].grid(axis = \"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdac91-0c8a-423e-89d5-c5a1322c40ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def random_episodes_v1(state_list):\n",
    "    \"\"\"\n",
    "    Plots random episodes for version 1\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    state_list: a list of states\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 4, figsize = (40, 10))\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(4):\n",
    "            random = np.random.randint(1001)\n",
    "            inside_temp = [array[0] for array in state_list[random]]\n",
    "            target_temp = [array[1] for array in state_list[random]]\n",
    "            x = [i for i in range(len(inside_temp))]\n",
    "            axes[i, j].plot(x, inside_temp)\n",
    "            axes[i, j].plot(x, target_temp)\n",
    "            axes[i, j].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7668639-52be-4e3a-bdbc-90410084edd8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def random_episodes_v2_3(state_list, episodes, max_steps):\n",
    "    \"\"\"\n",
    "    Plots random episodes for versions 2 and 3\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    state_list: a list of states\n",
    "    episodes: an integer amount of total episodes\n",
    "    max_steps: an integer amount of total steps\n",
    "    \"\"\"\n",
    "    x = [i for i in range(max_steps)]\n",
    "    fig, axes = plt.subplots(2, 4, figsize = (40, 10))\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(4):\n",
    "            random = np.random.randint(episodes + 1)\n",
    "            inside_temp = [array[0] for array in state_list[random]]\n",
    "            outside_temp = [array[1] for array in state_list[random]]\n",
    "            target_temp = [array[2] for array in state_list[random]]\n",
    "            axes[i, j].plot(x, inside_temp)\n",
    "            axes[i, j].plot(x, outside_temp, alpha = 0.3)\n",
    "            axes[i, j].plot(x, target_temp, \"--\", alpha = 0.5)\n",
    "            axes[i, j].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923578e-50bf-4bca-a3bd-53cbeddde12d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def random_episodes_v4(state_list, episodes, max_steps):\n",
    "    \"\"\"\n",
    "    Plots random episodes for version 4\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    state_list: a list of states\n",
    "    episodes: an integer amount of total episodes\n",
    "    max_steps: an integer amount of total steps\n",
    "    \"\"\"\n",
    "    x = [i for i in range(max_steps)]\n",
    "    fig, axes = plt.subplots(1, 6, figsize = (30, 3))\n",
    "\n",
    "    for j in range(6):\n",
    "        random = np.random.randint(episodes + 1)\n",
    "        inside_temp = [array[0] for array in state_list[random]]\n",
    "        outside_temp = [array[1] for array in state_list[random]]\n",
    "        target_temp = [array[3] for array in state_list[random]]\n",
    "        axes[j].plot(x, inside_temp)\n",
    "        axes[j].plot(x, outside_temp, alpha = 0.3)\n",
    "        axes[j].plot(x, target_temp, \"--\", alpha = 0.5)\n",
    "        axes[j].grid(alpha = 0.25)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3b09a-1a3c-4cf1-a35a-399d98c34267",
   "metadata": {},
   "source": [
    "# House Temperature Version 1.0 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b56a6-688d-491d-a38b-f3b16f74f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v1_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_1, state_dim = 4, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "ddqn_mse_rewards_v1_0, ddqn_mse_actions_v1_0, ddqn_mse_states_v1_0 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                             file_name = \"ddqn_mse_htv1_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b4e3f-e558-4415-aeaa-b5b4077afa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"Do Nothing\", 1: \"Window Switch\", 2: \"Heater Switch\"}\n",
    "\n",
    "plot_ra(max_steps = 50, rewards = ddqn_mse_rewards_v1_0, actions = ddqn_mse_actions_v1_0, action_space = action_space, version = \"V1.0\")\n",
    "\n",
    "random_episodes_v1(state_list = ddqn_mse_states_v1_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267b4f9-8ddc-499f-9134-85dab0eb56cb",
   "metadata": {},
   "source": [
    "# House Temperature Version 2.0 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddccf68d-88bb-4fed-8b04-d4dedb2272b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v2_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_2, state_dim = 7, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "ddqn_mse_rewards_v2_0, ddqn_mse_actions_v2_0, ddqn_mse_states_v2_0 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                             file_name = \"ddqn_mse_htv2_0\")\n",
    "\n",
    "in_target_v2(ddqn_mse_states_v2_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6741a58-610d-4815-86ee-696659405c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"Do Nothing\", 1: \"Heater Switch\", 2: \"Cooler Switch\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = ddqn_mse_rewards_v2_0, actions = ddqn_mse_actions_v2_0, action_space = action_space, version = \"V2.0\")\n",
    "\n",
    "random_episodes_v2_3(state_list = ddqn_mse_states_v2_0, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b159b540-c6ab-4792-ae9b-3d03cf4c1727",
   "metadata": {},
   "source": [
    "### Version 2.0 with Extended Min/Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7918db-73fd-4153-b03a-4f4e733fc9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v2_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_2, state_dim = 7, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "options = {\"temp_min\": -20, \"temp_max\": 50}\n",
    "\n",
    "v2_0_rewards_min_max, v2_0_actions_min_max, v2_0_states_min_max = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                          file_name = \"ddqn_mse_htv2_0\",options = options)\n",
    "\n",
    "in_target_v2(v2_0_states_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3703779-8d04-4da2-8f43-b520a901cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"Do Nothing\", 1: \"Heater Switch\", 2: \"Cooler Switch\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = v2_0_rewards_min_max, actions = v2_0_actions_min_max, action_space = action_space, version = \"V2.1\")\n",
    "\n",
    "random_episodes_v2_3(state_list = v2_0_states_min_max, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aaba9e-93a7-4810-8da4-f08d5f7448e3",
   "metadata": {},
   "source": [
    "### Version 2.0 with Different Outside Temperature Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec13b620-c52c-4bc5-80d8-d72255dd39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v2_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_2, state_dim = 7, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "options = {\"outside_temp_curve\": [np.random.uniform(0, 31) for i in range(576)]}\n",
    "\n",
    "v2_0_rewards_outside_1, v2_0_actions_outside_1, v2_0_states_outside_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                                file_name = \"ddqn_mse_htv2_0\",options = options)\n",
    "\n",
    "in_target_v2(v2_0_states_outside_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42be6045-f799-48ee-8b04-6c977bdab64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"Do Nothing\", 1: \"Heater Switch\", 2: \"Cooler Switch\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = v2_0_rewards_outside_1, actions = v2_0_actions_outside_1, action_space = action_space, version = \"V2.1\")\n",
    "\n",
    "random_episodes_v2_3(state_list = v2_0_states_outside_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfbd9e-a319-46ac-a408-1fc31f83ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v2_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_2, state_dim = 7, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "options = {\"outside_temp_curve\": 15 * np.sin(10 * env.x) + 15}\n",
    "\n",
    "v2_0_rewards_outside_2, v2_0_actions_outside_2, v2_0_states_outside_2 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                                file_name = \"ddqn_mse_htv2_0\",options = options)\n",
    "\n",
    "in_target_v2(v2_0_states_outside_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d8ba8-d8d4-485f-8539-246cd14663c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"Do Nothing\", 1: \"Heater Switch\", 2: \"Cooler Switch\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = v2_0_rewards_outside_2, actions = v2_0_actions_outside_2, action_space = action_space, version = \"V2.1\")\n",
    "\n",
    "random_episodes_v2_3(state_list = v2_0_states_outside_2, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ba022-d7f4-477a-ae3e-e6f5c9ee2b75",
   "metadata": {},
   "source": [
    "# House Temperature Version 2.1 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b30ff8-dd20-4e20-8cea-ce204ddd0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v2_1() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_2, state_dim = 7, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "ddqn_mse_rewards_v2_1, ddqn_mse_actions_v2_1, ddqn_mse_states_v2_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                             file_name = \"ddqn_mse_htv2_1\")\n",
    "\n",
    "in_target_v2(ddqn_mse_states_v2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b056b81-ff10-4cc3-989e-b49271a80212",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"Do Nothing\", 1: \"Heater Switch\", 2: \"Cooler Switch\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = ddqn_mse_rewards_v2_1, actions = ddqn_mse_actions_v2_1, action_space = action_space, version = \"V2.1\")\n",
    "\n",
    "random_episodes_v2_3(state_list = ddqn_mse_states_v2_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa33cf93-9db8-4af4-8823-2a0b75fc14cc",
   "metadata": {},
   "source": [
    "### Version 2.1 with Extended Min/Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c0d8f-7552-4786-ab5d-5b874d7348f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v2_1() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_2, state_dim = 7, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "options = {\"temp_min\": -20, \"temp_max\": 50}\n",
    "\n",
    "v2_1_rewards_min_max, v2_1_actions_min_max, v2_1_states_min_max = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                          file_name = \"ddqn_mse_htv2_1\",options = options)\n",
    "in_target_v2(v2_1_states_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a6e72-6f91-461a-90c7-dabb7b42fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"Do Nothing\", 1: \"Heater Switch\", 2: \"Cooler Switch\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = v2_1_rewards_min_max, actions = v2_1_actions_min_max, action_space = action_space, version = \"V2.1\")\n",
    "\n",
    "random_episodes_v2_3(state_list = v2_1_states_min_max, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2272e-9743-4944-8981-63d90ca571e5",
   "metadata": {},
   "source": [
    "### Version 2.1 with Different Outside Temperature Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c042a-d98d-460e-ab38-ce8cd84ca5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v2_1() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_2, state_dim = 7, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "options = {\"outside_temp_curve\": [np.random.uniform(0, 31) for i in range(576)]}\n",
    "\n",
    "v2_1_rewards_outside_1, v2_1_actions_outside_1, v2_1_states_outside_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                                file_name = \"ddqn_mse_htv2_1\",options = options)\n",
    "\n",
    "in_target_v2(v2_1_states_outside_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c26d9-0c6a-4045-8643-1479124a5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"Do Nothing\", 1: \"Heater Switch\", 2: \"Cooler Switch\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = v2_1_rewards_outside_1, actions = v2_1_actions_outside_1, action_space = action_space, version = \"V2.1\")\n",
    "\n",
    "random_episodes_v2_3(state_list = v2_1_states_outside_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a352166-c93a-449e-92ba-483a0fb69b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v2_1() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_2, state_dim = 7, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "options = {\"outside_temp_curve\": 15 * np.sin(10 * env.x) + 15}\n",
    "\n",
    "v2_1_rewards_outside_2, v2_1_actions_outside_2, v2_1_states_outside_2 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                                file_name = \"ddqn_mse_htv2_1\",options = options)\n",
    "\n",
    "in_target_v2(v2_1_states_outside_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afb2a2-ecf1-46ea-806a-27f94cfbce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"Do Nothing\", 1: \"Heater Switch\", 2: \"Cooler Switch\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = v2_1_rewards_outside_2, actions = v2_1_actions_outside_2, action_space = action_space, version = \"V2.1\")\n",
    "\n",
    "random_episodes_v2_3(state_list = v2_1_states_outside_2, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0457b8f-a283-4195-bf55-e9988f48ea41",
   "metadata": {},
   "source": [
    "# House Temperature Version 3.0 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11d4c7-cc67-470e-bd35-98a6df0187e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v3_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 8, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "ddqn_mse_rewards_v3_0, ddqn_mse_actions_v3_0, ddqn_mse_states_v3_0 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                             file_name = \"ddqn_mse_htv3_0\")\n",
    "\n",
    "in_target_v3(ddqn_mse_states_v3_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91e81e-ccb8-4aa2-9208-9c7d6b59862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = ddqn_mse_rewards_v3_0, actions = ddqn_mse_actions_v3_0, action_space = action_space, version = \"V3.0\")\n",
    "\n",
    "random_episodes_v2_3(state_list = ddqn_mse_states_v3_0, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afda591-7b8a-4bf1-beeb-9258aa6673a0",
   "metadata": {},
   "source": [
    "# House Temperature Version 3.1 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf4383-efc3-4aa8-83e3-26a192ba99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v3_1() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 8, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "ddqn_mse_rewards_v3_1, ddqn_mse_actions_v3_1, ddqn_mse_states_v3_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                             file_name = \"ddqn_mse_htv3_1\")\n",
    "\n",
    "in_target_v3(ddqn_mse_states_v3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff9d8a-a469-431c-bf0f-9f6bd09b9ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = ddqn_mse_rewards_v3_1, actions = ddqn_mse_actions_v3_1, action_space = action_space, version = \"V3.1\")\n",
    "\n",
    "random_episodes_v2_3(state_list = ddqn_mse_states_v3_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218eca84-c3c1-40ed-9b15-b26fd9387614",
   "metadata": {},
   "source": [
    "# House Temperature Version 4.0 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a7259-1ff9-4cb3-b0e7-3c1f7a90986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v4_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "ddqn_mse_rewards_v4_0, ddqn_mse_actions_v4_0, ddqn_mse_states_v4_0 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                             file_name = \"htv4_0/7_htv4_0\")\n",
    "\n",
    "in_target_v4(ddqn_mse_states_v4_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacbf00-ddd1-447e-88bc-f378aa007a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = ddqn_mse_rewards_v4_0, actions = ddqn_mse_actions_v4_0, action_space = action_space, version = \"V4.0\")\n",
    "\n",
    "random_episodes_v4(state_list = ddqn_mse_states_v4_0, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c3f3d-a924-465f-9a59-44d3464b10f9",
   "metadata": {},
   "source": [
    "## 4.0 Switch Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601133da-a57c-4ec3-836d-5416687f6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"switch_value\": 12}\n",
    "env = ht.house_temp_v4_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "sv_12_rewards_v4_0, sv_12_actions_v4_0, sv_12_states_v4_0 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                    file_name = \"htv4_0/7_htv4_0\", options = options)\n",
    "\n",
    "in_target_v4(sv_12_states_v4_0, switch_value = options[\"switch_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5320c503-7a85-42ce-830a-204352cac037",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = sv_12_rewards_v4_0, actions = sv_12_actions_v4_0, action_space = action_space, version = \"Switch: 12 | V4.0\")\n",
    "\n",
    "random_episodes_v4(state_list = sv_12_states_v4_0, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fede0d-f0fb-437f-b498-0e341b3fb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"switch_value\": 144}\n",
    "env = ht.house_temp_v4_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "sv_144_rewards_v4_0, sv_144_actions_v4_0, sv_144_states_v4_0 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                       file_name = \"htv4_0/7_htv4_0\", options = options)\n",
    "\n",
    "in_target_v4(sv_144_states_v4_0, switch_value = options[\"switch_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd69d66-a57c-488f-9824-bdbbb366ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = sv_144_rewards_v4_0, actions = sv_144_actions_v4_0, action_space = action_space, version = \"Switch: 144 | V4.0\")\n",
    "\n",
    "random_episodes_v4(state_list = sv_144_states_v4_0, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b8a7a-dd09-45e1-bd62-38553cc14760",
   "metadata": {},
   "source": [
    "## 4.0 Different Planet? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa0b90-fcc6-4063-9db2-64f12ea974bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"seasonal_variation\": {\"mean\": 50.0, \"fluctuation\": 5.0, \"noise\": (-3, 3), \"temp_min\": 40, \"temp_max\": 60}, \"inside_temp\": 50.0}\n",
    "env = ht.house_temp_v4_0() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "dp_rewards_v4_0, dp_actions_v4_0, dp_states_v4_0 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                           file_name = \"htv4_0/7_htv4_0\", options = options)\n",
    "\n",
    "in_target_v4(dp_states_v4_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7df883-d9f1-4e68-adb1-0b0fb36d772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = dp_rewards_v4_0, actions = dp_actions_v4_0, action_space = action_space, version = \"Different Planet | V4.0\")\n",
    "\n",
    "random_episodes_v4(state_list = dp_states_v4_0, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be991ed-895c-40f9-a829-ae6dc0e1b178",
   "metadata": {},
   "source": [
    "## 4.0 Temperature Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118c84ce-2647-4e4c-8f38-9eeb2e1e0079",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v4_0() \n",
    "options = {\"low_change\": 0, \"high_change\": 4}\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "td_rewards_v4_0, td_actions_v4_0, td_states_v4_0 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                           file_name = \"htv4_0/7_htv4_0\", options = options)\n",
    "\n",
    "in_target_v4(td_states_v4_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b9209-de0e-461a-af02-3767ed21f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = td_rewards_v4_0, actions = td_actions_v4_0, action_space = action_space, version = \"Temperature Distance | V4.0\")\n",
    "\n",
    "random_episodes_v4(state_list = td_states_v4_0, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae06df-69f4-4a54-acd7-1e9b44416505",
   "metadata": {},
   "source": [
    "## 4.0 Switch with Temperature Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734dfb36-2a47-480e-aa3b-f115a7a82f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v4_0() \n",
    "options = {\"low_change\": 0, \"high_change\": 2, \"switch_value\": 8}\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "swtd_rewards_v4_0, swtd_actions_v4_0, swtd_states_v4_0 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                 file_name = \"htv4_0/7_htv4_0\", options = options)\n",
    "\n",
    "in_target_v4(swtd_states_v4_0, switch_value = options[\"switch_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46ac8d-7ff8-4e55-84e6-b490f3a5ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = swtd_rewards_v4_0, actions = swtd_actions_v4_0, action_space = action_space, version = \"V4.1\")\n",
    "\n",
    "random_episodes_v4(state_list = swtd_states_v4_0, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d128372-d540-4be2-be2d-e331dc43ca8e",
   "metadata": {},
   "source": [
    "# House Temperature Version 4.1 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c1eca-46d9-4316-ba4d-7c819a6317fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v4_1() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "ddqn_mse_rewards_v4_1, ddqn_mse_actions_v4_1, ddqn_mse_states_v4_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                             file_name = \"htv4_1/6_htv4_1\")\n",
    "\n",
    "in_target_v4(ddqn_mse_states_v4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030e982-b48f-476d-a095-bcb141a539a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = ddqn_mse_rewards_v4_1, actions = ddqn_mse_actions_v4_1, action_space = action_space, version = \"V4.1\")\n",
    "\n",
    "random_episodes_v4(state_list = ddqn_mse_states_v4_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b2316-1934-4248-b0ce-f1aec4b12be0",
   "metadata": {},
   "source": [
    "## 4.1 Switch Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe5dc4-0d1e-4313-8913-4da2ac7909f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"switch_value\": 12}\n",
    "env = ht.house_temp_v4_1() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "sv_12_rewards_v4_1, sv_12_actions_v4_1, sv_12_states_v4_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                    file_name = \"htv4_1/6_htv4_1\", options = options)\n",
    "\n",
    "in_target_v4(sv_12_states_v4_1, switch_value = options[\"switch_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650567c0-cdb5-49fa-bd02-b206ab5c2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = sv_12_rewards_v4_1, actions = sv_12_actions_v4_1, action_space = action_space, version = \"Switch: 12 | V4.1\")\n",
    "\n",
    "random_episodes_v4(state_list = sv_12_states_v4_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e19914-daa6-4e83-94b2-0f34e348e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"switch_value\": 144}\n",
    "env = ht.house_temp_v4_1() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "sv_144_rewards_v4_1, sv_144_actions_v4_1, sv_144_states_v4_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                       file_name = \"htv4_1/6_htv4_1\", options = options)\n",
    "\n",
    "in_target_v4(sv_144_states_v4_1, switch_value = options[\"switch_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a659f-8333-4233-96bd-7fc149fadabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = sv_144_rewards_v4_1, actions = sv_144_actions_v4_1, action_space = action_space, version = \"Switch: 144 | V4.1\")\n",
    "\n",
    "random_episodes_v4(state_list = sv_144_states_v4_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6394dbda-ab1b-4159-aad9-fef6d8664232",
   "metadata": {},
   "source": [
    "## 4.1 Different Planet? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e00e9-99bd-43f0-8b94-8f2e4456bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"seasonal_variation\": {\"mean\": 50.0, \"fluctuation\": 10.0, \"noise\": (-3, 3), \"temp_min\": 40, \"temp_max\": 60}, \"inside_temp\": 50.0}\n",
    "env = ht.house_temp_v4_1() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "dp_rewards_v4_1, dp_actions_v4_1, dp_states_v4_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                           file_name = \"htv4_1/6_htv4_1\", options = options)\n",
    "\n",
    "in_target_v4(dp_states_v4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55122457-8693-4259-86de-64f115875576",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = dp_rewards_v4_1, actions = dp_actions_v4_1, action_space = action_space, version = \"Different Planet | V4.1\")\n",
    "\n",
    "random_episodes_v4(state_list = dp_states_v4_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aee331-eb68-43bf-8714-af4d978e771e",
   "metadata": {},
   "source": [
    "## 4.1 Temperature Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4f17e-31f9-458c-84a3-7a8ce7cf7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v4_1() \n",
    "options = {\"low_change\": 0, \"high_change\": 4}\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "td_rewards_v4_1, td_actions_v4_1, td_states_v4_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                           file_name = \"htv4_1/6_htv4_1\", options = options)\n",
    "\n",
    "in_target_v4(td_states_v4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b8ed36-56d4-41ca-8835-d362b5cc32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = td_rewards_v4_1, actions = td_actions_v4_1, action_space = action_space, version = \"Max Starting Temperature | V4.1\")\n",
    "\n",
    "random_episodes_v4(state_list = td_states_v4_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc4045-e6c6-4ee5-827e-2b49202f7871",
   "metadata": {},
   "source": [
    "## 4.1 Switch with Temperature Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1839c0-2bff-47a2-8f74-7d7c3f8994b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v4_1() \n",
    "options = {\"low_change\": 0, \"high_change\": 2, \"switch_value\": 8}\n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "swtd_rewards_v4_1, swtd_actions_v4_1, swtd_states_v4_1 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                 file_name = \"htv4_1/6_htv4_1\", options = options)\n",
    "\n",
    "in_target_v4(swtd_states_v4_1, switch_value = options[\"switch_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7812068c-52de-4e6f-9d8d-b823a62f79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = swtd_rewards_v4_1, actions = swtd_actions_v4_1, action_space = action_space, version = \"V4.1\")\n",
    "\n",
    "random_episodes_v4(state_list = swtd_states_v4_1, episodes = 1000, max_steps = 288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c00cb8-d902-430c-991d-34e4c122ba71",
   "metadata": {},
   "source": [
    "# House Temperature Version 4.2 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dbe423-b0f9-47a2-b687-97b6f902c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ht.house_temp_v4_2() \n",
    "agent = ddqn_agent.ddqn_agent_mse(model = house_temp_model_3, state_dim = 9, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                  epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "ddqn_mse_rewards_v4_2, ddqn_mse_actions_v4_2, ddqn_mse_states_v4_2 = testing(env = env, agent = agent, n_episodes = 1000, \n",
    "                                                                             file_name = \"trial_runs/ddqn_mse_htv4_2\")\n",
    "\n",
    "in_target_v4(ddqn_mse_states_v4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb070c9-1a94-401a-b593-b2a1285df36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {0: \"All Off\", 1: \"Heater On\", 2: \"Cooler On\", 3: \"Window On\", \n",
    "                4: \"Heater/Cooler On\", 5: \"Heater/Window On\", 6: \"Cooler/Window On\", 7: \"All On\"}\n",
    "\n",
    "plot_ra(max_steps = 288, rewards = ddqn_mse_rewards_v4_2, actions = ddqn_mse_actions_v4_2, action_space = action_space, version = \"V4.2\")\n",
    "\n",
    "random_episodes_v4(state_list = ddqn_mse_states_v4_2, episodes = 1000, max_steps = 288)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
