{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45851a8-c771-49ed-bce3-35a41ff0dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import environments.mountain_car as mc\n",
    "from useful import trees\n",
    "from agents import dqn_agent\n",
    "from agents import ddqn_agent\n",
    "from agents import pddqn_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02a2cf-f7fc-4981-8373-c025059691a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ef72c-974f-4201-8385-13c62ce1bc40",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2825bb-d5c1-4e04-8d4a-f12eca618799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mountain_car_model_1(nn.Module): \n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(mountain_car_model_1, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_observations, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a05a160-7dac-42f8-b43c-784d30340e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dueling_dqn(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(dueling_dqn, self).__init__()\n",
    "        self.n_observations = n_observations\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_observations, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.state_value = nn.Sequential(\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(256, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.shape == torch.Size([self.n_observations]):\n",
    "            x = x.unsqueeze(0)\n",
    "        \n",
    "        x = self.model(x)\n",
    "        value = self.state_value(x)\n",
    "        advantage = self.advantage(x)\n",
    "        q_value = value + (advantage - torch.mean(advantage, dim = 1, keepdim = True))\n",
    "        \n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976bdb44-d900-4187-b279-c93257466c84",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e2f9c-aad0-42bf-ad27-86ae04c32a1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def testing(env, agent, n_episodes, file_name, global_episode, render):\n",
    "    \"\"\"\n",
    "    Testing agents for the mountain car environment\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    env: gym environment\n",
    "    agent: training agent\n",
    "    n_episodes: an integer for the number of episodes to run\n",
    "    file_name: a string name of the model to import\n",
    "    global_episode: an integer for the current episode in training\n",
    "    render: a boolean if the episode should be printed\n",
    "    ------\n",
    "    Output\n",
    "    ------\n",
    "    reward_list: mean reward for all validation episodes\n",
    "    \"\"\"\n",
    "    agent.main_model.load_state_dict(torch.load(f\"model_weights/mountain_car/{file_name}.pth\"))\n",
    "    agent.main_model.eval()\n",
    "    reward_list = []\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        state, _ = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        for step in range(env.max_steps):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, termination, truncation, _ = env.step(action)\n",
    "\n",
    "            if (global_episode + 1) % 100 == 0 and render and render_count == 0:\n",
    "                print(f\"Episode: {global_episode + 1} | Reward: {reward:.2f}\")\n",
    "                env.render()\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if termination or truncation:\n",
    "                break\n",
    "\n",
    "        reward_list.append(total_reward)\n",
    "\n",
    "    return np.mean(reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af20919-42ac-4f00-bb48-a5705ab03d8e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def training(env, agent, v_agent, n_episodes, file_name, target_update_steps, version, render = False, optimal = False):\n",
    "    \"\"\"\n",
    "    Training agents for the mountain car environment. Provides the mean positions as a graph with the mean rewards. \n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    env: gym environment\n",
    "    agent: training agent\n",
    "    v_agent: validation agent\n",
    "    n_episodes: number of episodes to run\n",
    "    file_name: file name for saving the model \n",
    "    target_update_steps: how many steps to update the target model\n",
    "    version: what is being tested\n",
    "    render: if the episode should be printed\n",
    "    optimal: boolean to take the best possible validation reward\n",
    "    ------\n",
    "    output\n",
    "    ------\n",
    "    validation_rewards: a list of average rewards per validation batch\n",
    "    \"\"\"\n",
    "    reward_list, validation_rewards, global_steps = [], [], 0\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        state, _ = env.reset()\n",
    "        steps_loss, position_list, total_reward = [], [], 0\n",
    "\n",
    "        for steps in range(env.max_steps):\n",
    "            global_steps += 1\n",
    "            if global_steps % target_update_steps == 0:\n",
    "                agent.update_target()\n",
    "            \n",
    "            action = agent.act(state)\n",
    "            next_state, reward, termination, truncation, _ = env.step(action)\n",
    "            agent.update_memory(state, action, reward, next_state, termination)\n",
    "            \n",
    "            loss = agent.train_step()\n",
    "            agent.decay_epsilon()\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "            if termination or truncation:\n",
    "                break\n",
    "\n",
    "        reward_list.append(total_reward)\n",
    "        torch.save(agent.main_model.state_dict(), f\"model_weights/mountain_car/{file_name}.pth\")\n",
    "\n",
    "        if (episode + 1) % 50 == 0:\n",
    "            validation_reward = testing(env, v_agent, 100, file_name, episode, render)\n",
    "            print(f\"Episode: {episode - 48} - {episode + 1} | Average reward: {validation_reward:.2f}\")\n",
    "            validation_rewards.append(validation_reward)\n",
    "            if validation_reward > -105.0 and optimal:\n",
    "                return reward_list, validation_rewards\n",
    "\n",
    "    plot_training(reward_list, version)\n",
    "                \n",
    "    return validation_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2d639-a65c-4f29-9b02-84dc12e67d3a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_training(rewards, version):\n",
    "    \"\"\"\n",
    "    Plots training episodes\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    rewards: a list of rewards\n",
    "    version: a string for the title\n",
    "    \"\"\"\n",
    "    x = [i for i in range(1, len(rewards) + 1)] \n",
    "\n",
    "    fig, axes = plt.subplots(figsize = (20, 3.333))\n",
    "\n",
    "    axes.scatter(x, rewards, s = 10)\n",
    "    axes.set_title(f\"Learning Progress | {version}\")\n",
    "    axes.set_ylabel(\"Total Reward\")\n",
    "    axes.set_xlabel(\"Training Episodes\")\n",
    "    axes.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da7c6d-d6a9-4668-a111-1847b74f987d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_validation(v_rewards_list, labels, version, size = (4.5, 3)):\n",
    "    \"\"\"\n",
    "    Plots validation rewards with shown standard deviation\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    v_rewards: a list of arrays of different training runs\n",
    "    legends: a list of strings for each label\n",
    "    title: a string for the title\n",
    "    size: a tuple for the dimensions of the graph\n",
    "    \"\"\"\n",
    "    x = [(i + 1)*50 for i in range(len(v_rewards_list[0][0]))]\n",
    "    fig, axes = plt.subplots(figsize = (size[0], size[1]))\n",
    "\n",
    "    for validation, legend in zip(v_rewards_list, labels):\n",
    "        mean, std = np.mean(validation, axis = 0), np.std(validation, axis = 0)\n",
    "        axes.plot(x, mean, label = legend)\n",
    "        axes.fill_between(x, mean - std, mean + std, alpha = 0.25)\n",
    "        \n",
    "    axes.set_title(f\"{version}\")\n",
    "    axes.set_ylabel(\"Average Total Reward\")\n",
    "    axes.set_xlabel(\"Episodes\")\n",
    "    axes.grid()\n",
    "    axes.legend(fontsize = 8)\n",
    "    axes.set_ylim(-205)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b6df3-f06c-4ee1-b167-260f3e604bd4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def best_curve(v_rewards_list, labels):\n",
    "    \"\"\"\n",
    "    Finds the curve closest to the mean\n",
    "    -----\n",
    "    Input\n",
    "    -----\n",
    "    v_rewards_list: a list of arrays of different training runs\n",
    "    labels: a list of strings for each label\n",
    "    \"\"\"\n",
    "    for validation in v_rewards_list:\n",
    "        global_mean = np.mean(validation, axis = 0) \n",
    "        for i in range(len(validation)):\n",
    "            print(f\"{np.mean((validation[i] - global_mean)**2, axis = 0):.2f} | {labels[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d928187-4d93-4ea9-b6bf-5b627a09174f",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e30b9-c892-4d63-8c5c-1102ea97b9ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_dqn = []\n",
    "file_name = [\"algorithms/dqn/mse_1\", \"algorithms/dqn/mse_2\", \"algorithms/dqn/mse_3\", \"algorithms/dqn/mse_4\", \"algorithms/dqn/mse_5\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "    \n",
    "    v_agent = dqn_agent.dqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                      epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = dqn_agent.dqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                    epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    dqn_mse_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                 target_update_steps = 1000, version = \"DQN\")\n",
    "\n",
    "    global_dqn.append(dqn_mse_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02406306-66a6-4c49-9ab2-796650fcadd2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ddqn = []\n",
    "file_name = [\"algorithms/ddqn/mse_1\", \"algorithms/ddqn/mse_2\", \"algorithms/ddqn/mse_3\", \"algorithms/ddqn/mse_4\", \"algorithms/ddqn/mse_5\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "    \n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ddqn_mse_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 1000, version = \"DDQN\")\n",
    "\n",
    "    global_ddqn.append(ddqn_mse_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882946b4-07d9-48b0-90dd-7e921cc95249",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_pddqn = []\n",
    "file_name = [\"algorithms/pddqn/mse_1\", \"algorithms/pddqn/mse_2\", \"algorithms/pddqn/mse_3\", \"algorithms/pddqn/mse_4\", \"algorithms/pddqn/mse_5\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "    \n",
    "    v_agent = pddqn_agent.pddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, alpha = 0, \n",
    "                                          beta = 0, lr = 0, epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 1, batch_size = 0, \n",
    "                                          n_episodes = 1, device = device)\n",
    "\n",
    "    agent = pddqn_agent.pddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, alpha = 0.7,\n",
    "                                        beta = 0.5, lr = 0.0005, epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, \n",
    "                                        batch_size = 128, n_episodes = 1500, device = device)\n",
    "\n",
    "    pddqn_mse_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                   target_update_steps = 1000, version = \"PDDQN\")\n",
    "\n",
    "    global_pddqn.append(pddqn_mse_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044e24a-986f-43eb-9538-0d14385a8e58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_dddqn = []\n",
    "file_name = [\"algorithms/dddqn/mse_1\", \"algorithms/ddqn/mse_2\", \"algorithms/dddqn/mse_3\", \"algorithms/dddqn/mse_4\", \"algorithms/dddqn/mse_5\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "    \n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = dueling_dqn, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = dueling_dqn, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    dddqn_mse_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                   target_update_steps = 1000, version = \"DDDQN\")\n",
    "\n",
    "    global_dddqn.append(dddqn_mse_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dacb04-10c1-47db-82ce-943a71c01055",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_dqn, global_ddqn, global_pddqn, global_dddqn]\n",
    "labels = [\"DQN\", \"DDQN\", \"PER\", \"Duelling\"]\n",
    "version = \"Algorithms\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5403248-0b94-471f-b426-5338712e2ffd",
   "metadata": {},
   "source": [
    "# Parameter Evaluation for Mountain Car Version 1\n",
    "### MSE VS Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67455a7d-6fe0-46e8-b3cf-525f6b58810e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_mse = []\n",
    "file_name = [\"parameters/loss/mse_1\", \"parameters/loss/mse_2\", \"parameters/loss/mse_3\", \"parameters/loss/mse_4\", \"parameters/loss/mse_5\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    mse_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                             target_update_steps = 1000, version = \"MSE\")\n",
    "\n",
    "    global_mse.append(mse_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d867b92a-0550-411b-bc00-2252e5b9efe5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_huber = []\n",
    "file_name = [\"parameters/loss/huber_1\", \"parameters/loss/huber_2\", \"parameters/loss/huber_3\", \"parameters/loss/huber_4\", \"parameters/loss/huber_5\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1() \n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_huber(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                          epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_huber(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                        epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    huber_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                               target_update_steps = 1000, version = \"Huber\")\n",
    "\n",
    "    global_huber.append(huber_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0150f23-a430-4949-bd60-5dcd098f7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_mse, global_huber]\n",
    "labels = [\"MSE\", \"Huber Loss\"]\n",
    "version = \"Loss Functions\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11727c2-4ed4-4db2-b64a-460119120527",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7857a9-0efc-4bd7-b916-78e3fc4d42a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_lr_0001 = []\n",
    "file_name = [\"parameters/lr/0001\", \"parameters/lr/0001\", \"parameters/lr/0001\", \"parameters/lr/0001\", \"parameters/lr/0001\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.001,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    lr_0001_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                 target_update_steps = 1000, version = \"0.001\")\n",
    "\n",
    "    global_lr_0001.append(lr_0001_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4e469-e14e-418a-8319-7e41ebcfc83b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_lr_000075 = []\n",
    "file_name = [\"parameters/lr/000075\", \"parameters/lr/000075\", \"parameters/lr/000075\", \"parameters/lr/000075\", \"parameters/lr/000075\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.00075,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    lr_000075_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                   target_update_steps = 1000, version = \"0.00075\")\n",
    "\n",
    "    global_lr_000075.append(lr_000075_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27788c21-3d5e-4327-97d3-338b55c16d76",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_lr_00005 = []\n",
    "file_name = [\"parameters/lr/00005\", \"parameters/lr/00005\", \"parameters/lr/00005\", \"parameters/lr/00005\", \"parameters/lr/00005\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    lr_00005_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 1000, version = \"0.0005\")\n",
    "\n",
    "    global_lr_00005.append(lr_00005_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47ac03-16a8-44c7-a0a7-a32a2c31c834",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_lr_000025 = []\n",
    "file_name = [\"parameters/lr/000025\", \"parameters/lr/000025\", \"parameters/lr/000025\", \"parameters/lr/000025\", \"parameters/lr/000025\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.00025,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    lr_000025_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                   target_update_steps = 1000, version = \"0.00025\")\n",
    "\n",
    "    global_lr_000025.append(lr_000025_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7b96c-2f68-4a6a-b5bd-ef0e17cf83de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_lr_00001 = []\n",
    "file_name = [\"parameters/lr/00001\", \"parameters/lr/00001\", \"parameters/lr/00001\", \"parameters/lr/00001\", \"parameters/lr/00001\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0001,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    lr_00001_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 1000, version = \"0.0001\")\n",
    "\n",
    "    global_lr_00001.append(lr_00001_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f587cb-1dc0-4fbb-8013-c82a973e37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_lr_0001, global_lr_000075, global_lr_00005, global_lr_000025, global_lr_00001]\n",
    "labels = [\"0.001\", \"0.00075\", \"0.0005\", \"0.00025\", \"0.0001\"]\n",
    "version = \"Learning Rates\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c47cd-7ab7-4f11-b1f3-2fa32e215ec1",
   "metadata": {},
   "source": [
    "## Epsilon Minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38ff99-aec5-4216-8556-ecb517d59be4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_em_01 = []\n",
    "file_name = [\"parameters/em/01\", \"parameters/em/01\", \"parameters/em/01\", \"parameters/em/01\", \"parameters/em/01\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1() \n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.1, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    em_01_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                               target_update_steps = 1000, version = \"0.1\")\n",
    "\n",
    "    global_em_01.append(em_01_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40318f74-bdb0-4d66-a314-9d97520e35f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_em_005 = []\n",
    "file_name = [\"parameters/em/005\", \"parameters/em/005\", \"parameters/em/005\", \"parameters/em/005\", \"parameters/em/005\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1() \n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.05, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    em_005_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                target_update_steps = 1000, version = \"0.05\")\n",
    "\n",
    "    global_em_005.append(em_005_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d6e52-df7c-47f6-beec-e5073b31459d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_em_001 = []\n",
    "file_name = [\"parameters/em/001\", \"parameters/em/001\", \"parameters/em/001\", \"parameters/em/001\", \"parameters/em/001\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1() \n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    em_001_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                target_update_steps = 1000, version = \"0.01\")\n",
    "\n",
    "    global_em_001.append(em_001_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee32f6-31e1-4b25-9239-9032256001cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_em_0001 = []\n",
    "file_name = [\"parameters/em/0001\", \"parameters/em/0001\", \"parameters/em/0001\", \"parameters/em/0001\", \"parameters/em/0001\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1() \n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.001, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    em_0001_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                 target_update_steps = 1000, version = \"0.001\")\n",
    "\n",
    "    global_em_0001.append(em_0001_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671b9f8-5a5d-451b-98e9-50ff440dbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_em_01, global_em_005, global_em_001, global_em_0001]\n",
    "labels = [\"0.1\", \"0.05\", \"0.01\", \"0.001\"]\n",
    "version = \"Epsilon Minimum\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83c47e-6283-4e8e-9896-bd75776f1cd4",
   "metadata": {},
   "source": [
    "## Decay Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250f3e4-b660-4627-a7bf-9a8d4b8fb897",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ds_100000 = []\n",
    "file_name = [\"parameters/ds/100000\", \"parameters/ds/100000\", \"parameters/ds/100000\", \"parameters/ds/100000\", \"parameters/ds/100000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 100000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ds_100000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                   target_update_steps = 1000, version = \"100000\")\n",
    "\n",
    "    global_ds_100000.append(ds_100000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c3765-fd1d-4dde-aa53-96e90dd462da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ds_50000 = []\n",
    "file_name = [\"parameters/ds/50000\", \"parameters/ds/50000\", \"parameters/ds/50000\", \"parameters/ds/50000\", \"parameters/ds/50000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 50000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ds_50000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 1000, version = \"50000\")\n",
    "\n",
    "    global_ds_50000.append(ds_50000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f235e-b652-421e-bcd8-f6bca213d750",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ds_20000 = []\n",
    "file_name = [\"parameters/ds/20000\", \"parameters/ds/20000\", \"parameters/ds/20000\", \"parameters/ds/20000\", \"parameters/ds/20000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ds_20000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 1000, version = \"20000\")\n",
    "\n",
    "    global_ds_20000.append(ds_20000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d876d2-021f-49d2-96c2-2c2790bdb7dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ds_10000 = []\n",
    "file_name = [\"parameters/ds/10000\", \"parameters/ds/10000\", \"parameters/ds/10000\", \"parameters/ds/10000\", \"parameters/ds/10000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 10000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ds_10000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 1000, version = \"10000\")\n",
    "\n",
    "    global_ds_10000.append(ds_10000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8247e-62bc-4007-a147-98d8de4d4b17",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ds_1000 = []\n",
    "file_name = [\"parameters/ds/1000\", \"parameters/ds/1000\", \"parameters/ds/1000\", \"parameters/ds/1000\", \"parameters/ds/1000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 1000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ds_1000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 1000, version = \"1000\")\n",
    "\n",
    "    global_ds_1000.append(ds_1000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5497fa-e741-47da-a82a-a7d21bbbfa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_ds_100000, global_ds_50000, global_ds_20000, global_ds_10000, global_ds_1000]\n",
    "labels = [\"100000\", \"50000\", \"20000\", \"10000\", \"1000\"]\n",
    "version = \"Decay Steps\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1f620-049f-4914-8a25-a5f35f98022b",
   "metadata": {},
   "source": [
    "## Memory Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4370f3-c271-418a-8d7a-060eff904e3e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_buffer_100000 = []\n",
    "file_name = [\"parameters/buffer/100000\", \"parameters/buffer/100000\", \"parameters/buffer/100000\", \"parameters/buffer/100000\", \"parameters/buffer/100000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 100000, batch_size = 128, device = device)\n",
    "\n",
    "    buffer_100000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                       target_update_steps = 1000, version = \"100000\")\n",
    "\n",
    "    global_buffer_100000.append(buffer_100000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85c702-0dfd-44e4-a67d-6ee265edbb68",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_buffer_50000 = []\n",
    "file_name = [\"parameters/buffer/50000\", \"parameters/buffer/50000\", \"parameters/buffer/50000\", \"parameters/buffer/50000\", \"parameters/buffer/50000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 50000, batch_size = 128, device = device)\n",
    "\n",
    "    buffer_50000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                      target_update_steps = 1000, version = \"50000\")\n",
    "\n",
    "    global_buffer_50000.append(buffer_50000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079d2d6-b49f-4f7c-ab86-a55d45d3df4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_buffer_20000 = []\n",
    "file_name = [\"parameters/buffer/20000\", \"parameters/buffer/20000\", \"parameters/buffer/20000\", \"parameters/buffer/20000\", \"parameters/buffer/20000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    buffer_20000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                      target_update_steps = 1000, version = \"20000\")\n",
    "\n",
    "    global_buffer_20000.append(buffer_20000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21bc150-0341-48e0-8636-b03b2cf66d34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_buffer_10000 = []\n",
    "file_name = [\"parameters/buffer/10000\", \"parameters/buffer/10000\", \"parameters/buffer/10000\", \"parameters/buffer/10000\", \"parameters/buffer/10000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 10000, batch_size = 128, device = device)\n",
    "\n",
    "    buffer_10000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                      target_update_steps = 1000, version = \"10000\")\n",
    "\n",
    "    global_buffer_10000.append(buffer_10000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fde747-51d4-4179-ba6d-3a11d930dfa6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_buffer_1000 = []\n",
    "file_name = [\"parameters/buffer/1000\", \"parameters/buffer/1000\", \"parameters/buffer/1000\", \"parameters/buffer/1000\", \"parameters/buffer/1000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 1000, batch_size = 128, device = device)\n",
    "\n",
    "    buffer_1000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                      target_update_steps = 1000, version = \"1000\")\n",
    "\n",
    "    global_buffer_1000.append(buffer_1000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d019c2d-516d-43da-a4d4-8a5df959bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_buffer_100000, global_buffer_50000, global_buffer_20000, global_buffer_10000, global_buffer_1000]\n",
    "labels = [\"100000\", \"50000\", \"20000\", \"10000\", \"1000\"]\n",
    "version = \"Memory Size\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c01b283-c944-411a-9f9b-492ea9d18186",
   "metadata": {},
   "source": [
    "## Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d18cb-670b-4c6a-ad90-03df81c70b14",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_batch_512 = []\n",
    "file_name = [\"parameters/batch/512\", \"parameters/batch/512\", \"parameters/batch/512\", \"parameters/batch/512\", \"parameters/batch/512\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 512, device = device)\n",
    "\n",
    "    batch_512_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                   target_update_steps = 1000, version = \"512\")\n",
    "\n",
    "    global_batch_512.append(batch_512_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e031323-dd5a-4108-92e3-17c2cd5737e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_batch_256 = []\n",
    "file_name = [\"parameters/batch/256\", \"parameters/batch/256\", \"parameters/batch/256\", \"parameters/batch/256\", \"parameters/batch/256\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 256, device = device)\n",
    "\n",
    "    batch_256_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                   target_update_steps = 1000, version = \"256\")\n",
    "\n",
    "    global_batch_256.append(batch_256_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034bd92-be49-44a6-b84c-ca93e311e058",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_batch_128 = []\n",
    "file_name = [\"parameters/batch/128\", \"parameters/batch/128\", \"parameters/batch/128\", \"parameters/batch/128\", \"parameters/batch/128\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    batch_128_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                   target_update_steps = 1000, version = \"128\")\n",
    "\n",
    "    global_batch_128.append(batch_128_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819d77b-1a9f-4cce-b34f-dce91e55479a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_batch_64 = []\n",
    "file_name = [\"parameters/batch/64\", \"parameters/batch/64\", \"parameters/batch/64\", \"parameters/batch/64\", \"parameters/batch/64\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 64, device = device)\n",
    "\n",
    "    batch_64_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 1000, version = \"64\")\n",
    "\n",
    "    global_batch_64.append(batch_64_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17505a8a-e8ef-42b0-899b-358c5fc3fb99",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_batch_32 = []\n",
    "file_name = [\"parameters/batch/32\", \"parameters/batch/32\", \"parameters/batch/32\", \"parameters/batch/32\", \"parameters/batch/32\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 32, device = device)\n",
    "\n",
    "    batch_32_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 1000, version = \"32\")\n",
    "\n",
    "    global_batch_32.append(batch_32_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d4c0d-d339-41f9-9c73-bb5a80584637",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_batch_512, global_batch_256, global_batch_128, global_batch_64, global_batch_32]\n",
    "labels = [\"512\", \"256\", \"128\", \"64\", \"32\"]\n",
    "version = \"Batch Size\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc5e44-51b9-4cef-b894-28bcd2d385b5",
   "metadata": {},
   "source": [
    "# Update Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f33d0f-4189-4bd3-9567-4d9ad492f732",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ut_10000 = []\n",
    "file_name = [\"parameters/ut/10000\", \"parameters/ut/10000\", \"parameters/ut/10000\", \"parameters/ut/10000\", \"parameters/ut/10000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ut_10000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                  target_update_steps = 10000, version = \"10000\")\n",
    "\n",
    "    global_ut_10000.append(ut_10000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5820d-ab30-4207-90cc-aaec1ae63e14",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ut_5000 = []\n",
    "file_name = [\"parameters/ut/5000\", \"parameters/ut/5000\", \"parameters/ut/5000\", \"parameters/ut/5000\", \"parameters/ut/5000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ut_5000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                 target_update_steps = 5000, version = \"5000\")\n",
    "\n",
    "    global_ut_5000.append(ut_5000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e97883-a2b9-4a49-9607-98ef90ab555c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ut_1000 = []\n",
    "file_name = [\"parameters/ut/1000\", \"parameters/ut/1000\", \"parameters/ut/1000\", \"parameters/ut/1000\", \"parameters/ut/1000\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ut_1000_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                 target_update_steps = 1000, version = \"1000\")\n",
    "\n",
    "    global_ut_1000.append(ut_1000_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7022c2d-50f2-49a0-bc0c-3404f6145ecc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ut_500 = []\n",
    "file_name = [\"parameters/ut/500\", \"parameters/ut/500\", \"parameters/ut/500\", \"parameters/ut/500\", \"parameters/ut/500\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ut_500_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                target_update_steps = 500, version = \"500\")\n",
    "\n",
    "    global_ut_500.append(ut_500_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550bc8b5-a60f-4325-b8fc-5a3601c13bc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_ut_100 = []\n",
    "file_name = [\"parameters/ut/100\", \"parameters/ut/100\", \"parameters/ut/100\", \"parameters/ut/100\", \"parameters/ut/100\"]\n",
    "for i in range(5):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0,\n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0,batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.01, decay_steps = 20000, buffer_size = 20000, batch_size = 128, device = device)\n",
    "\n",
    "    ut_100_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                target_update_steps = 100, version = \"100\")\n",
    "\n",
    "    global_ut_100.append(ut_100_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2a50e-21d0-45ef-b7da-96da76b9cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_ut_10000, global_ut_5000, global_ut_1000, global_ut_500, global_ut_100]\n",
    "labels = [\"10000\", \"5000\", \"1000\", \"500\", \"100\"]\n",
    "version = \"Target Network Update Frequency\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f983b-cb8a-4c03-a499-8c8d459c5a78",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033ffe7-e9c0-4879-be75-8a9be3e99b38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_train_v1 = []\n",
    "file_name = [\"mcv1_1\", \"mcv1_2\", \"mcv1_3\", \"mcv1_4\", \"mcv1_5\", \"mcv1_6\", \"mcv1_7\", \"mcv1_8\", \"mcv1_9\", \"mcv1_10\"]\n",
    "for i in range(10):\n",
    "    env = mc.mountain_car_discrete_v1()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.05, decay_steps = 50000, buffer_size = 100000, batch_size = 512, device = device)\n",
    "\n",
    "    trainv1_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1500, file_name = file_name[i], \n",
    "                                 target_update_steps = 1000, version = \" \")\n",
    "    \n",
    "    global_train_v1.append(trainv1_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7413e-867d-46ff-b331-9985725b6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_train_v1]\n",
    "labels = [\"MC.V1\"]\n",
    "version = \"Mountain Car Version 1\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe0a85-b87b-486e-bfe3-2a27cf783289",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_train_v2 = []\n",
    "file_name = [\"mcv2_1\", \"mcv2_2\", \"mcv2_3\", \"mcv2_4\", \"mcv2_5\", \"mcv2_6\", \"mcv2_7\", \"mcv2_8\", \"mcv2_9\", \"mcv2_10\"]\n",
    "for i in range(10):\n",
    "    env = mc.mountain_car_discrete_v2()\n",
    "\n",
    "    v_agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0, lr = 0, \n",
    "                                        epsilon = 0, epsilon_min = 0, decay_steps = 1, buffer_size = 0, batch_size = 0, device = device)\n",
    "\n",
    "    agent = ddqn_agent.ddqn_agent_mse(model = mountain_car_model_1, state_dim = 2, action_dim = env.action_space.n, gamma = 0.99, lr = 0.0005,\n",
    "                                      epsilon = 1.0, epsilon_min = 0.05, decay_steps = 50000, buffer_size = 100000, batch_size = 512, device = device)\n",
    "\n",
    "    trainv2_v_rewards = training(env = env, agent = agent, v_agent = v_agent, n_episodes = 1350, file_name = file_name[i], \n",
    "                                 target_update_steps = 1000, version = \" \")\n",
    "\n",
    "    global_train_v2.append(trainv2_v_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c770e27-4090-452f-a4a5-3cf9671d8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_train_v2]\n",
    "labels = [\"MC.V2\"]\n",
    "version = \"Mountain Car Version 2\"\n",
    "\n",
    "plot_validation(v_rewards_list = v_rewards_list, labels = labels, version = version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bef40-75d5-4124-93a3-9f9451c277d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_train_v1]\n",
    "labels = [\"mcv1_1\", \"mcv1_2\", \"mcv1_3\", \"mcv1_4\", \"mcv1_5\", \"mcv1_6\", \"mcv1_7\", \"mcv1_8\", \"mcv1_9\", \"mcv1_10\"]\n",
    "\n",
    "best_curve(v_rewards_list = v_rewards_list, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c7369-5c62-4738-b658-633aeeead6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rewards_list = [global_train_v2]\n",
    "labels = [\"mcv2_1\", \"mcv2_2\", \"mcv2_3\", \"mcv2_4\", \"mcv2_5\", \"mcv2_6\", \"mcv2_7\", \"mcv2_8\", \"mcv2_9\", \"mcv2_10\"]\n",
    "\n",
    "best_curve(v_rewards_list = v_rewards_list, labels = labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
